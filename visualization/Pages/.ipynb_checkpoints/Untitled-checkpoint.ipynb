{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a5f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mocid\\miniconda3\\envs\\ironhack_project_1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os #needed for the API for example (to access environment variables)\n",
    "from dotenv import load_dotenv #needed to load environmet variables to this project\n",
    "import tensorflow as tf #for the RNN (recurring neural network)\n",
    "import keras #for the RNN (recurring neural network)\n",
    "from keras import layers #for the RNN (recurring neural network)\n",
    "import numpy as np\n",
    "import os #to interact with the folders of this project\n",
    "import time #this will allow us to create a time buffer between each lyrics extraction \n",
    "import lyricsgenius as lg #(to work with the genius.com API)\n",
    "import requests #to request data from Genius API (sending http requests)\n",
    "import json #to read the extracted info from the API (encoding and decoding the info we got)\n",
    "import pandas as pd\n",
    "from requests.exceptions import SSLError #to handle exceptions when fetching data from Genius\n",
    "import re\n",
    "import logging #for the logbook I created to record the errors while fetching lyrics from the API genius\n",
    "from nltk.tokenize import word_tokenize #Natural Language Toolkit to count words and single words and process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2dde62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Path: C:\\Users\\mocid\\Ironhack\\Final-Project\\Rap_GPT_06_12\n"
     ]
    }
   ],
   "source": [
    "grandparent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "model_path = os.path.join(grandparent_directory, \"Rap_GPT_06_12\")\n",
    "print(\"Model Path:\", model_path)\n",
    "one_step_reloaded = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99cfcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write something for the RAP GPT to pick up on:Hello world\n"
     ]
    }
   ],
   "source": [
    "text_introduction_for_rap_GPT = input(\"Write something for the RAP GPT to pick up on:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ee8d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world (Ain't a whiff of granden\r\n",
      "And here's an ode to the worst of my days\r\n",
      "I've been working away\r\n",
      "But the sky's been looking down with a smile\r\n",
      "Watchin' me proseet motherfuckers and the heins on the clouds in bold letters\r\n",
      "If hoes leve me cheddart, we on the special was and that I spill like that\r\n",
      "I got a six-pack of bare skill that I spill like that\r\n",
      "And everybody know (That shit with my eyes like\r\n",
      "(I handle of a one, yeah, this fucking down her pants\r\n",
      "She like \"I said, \"Capital STEEZ\", I say there's work of Garda\r\n",
      "Fush my oppressor, so they can't be second greatest\r\n",
      "This shit is legimal dause, 'cause we don't really show it\r\n",
      "\r\n",
      "Right on time, you are my love\r\n",
      "This ain't nothing like consistence, persistence\r\n",
      "When we switching positions\r\n",
      "My mission's to put you in the best conditions\r\n",
      "Right on trices in my back got malf mex\r\n",
      "And that's just how I do this\r\n",
      "Sex many times I gotta tell you I don't need no feelin' pirase\r\n",
      "Bag, but it's all a part of the business, don't take it\r\n",
      "And I hope he  \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.2211339473724365\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([text_introduction_for_rap_GPT])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack_project_1",
   "language": "python",
   "name": "ironhack_project_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
