{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a5f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mocid\\miniconda3\\envs\\ironhack_project_1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os #needed for the API for example (to access environment variables)\n",
    "from dotenv import load_dotenv #needed to load environmet variables to this project\n",
    "import tensorflow as tf #for the RNN (recurring neural network)\n",
    "import keras #for the RNN (recurring neural network)\n",
    "from keras import layers #for the RNN (recurring neural network)\n",
    "import numpy as np\n",
    "import os #to interact with the folders of this project\n",
    "import time #this will allow us to create a time buffer between each lyrics extraction \n",
    "import lyricsgenius as lg #(to work with the genius.com API)\n",
    "import requests #to request data from Genius API (sending http requests)\n",
    "import json #to read the extracted info from the API (encoding and decoding the info we got)\n",
    "import pandas as pd\n",
    "from requests.exceptions import SSLError #to handle exceptions when fetching data from Genius\n",
    "import re\n",
    "import logging #for the logbook I created to record the errors while fetching lyrics from the API genius\n",
    "from nltk.tokenize import word_tokenize #Natural Language Toolkit to count words and single words and process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2dde62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Path: C:\\Users\\mocid\\Ironhack\\Final-Project\\Rap_GPT_06_12\n"
     ]
    }
   ],
   "source": [
    "grandparent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "model_path = os.path.join(grandparent_directory, \"Rap_GPT_06_12\")\n",
    "print(\"Model Path:\", model_path)\n",
    "one_step_reloaded = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99cfcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write something for the RAP GPT to pick up on:started from data collection now we here with tha team!\n"
     ]
    }
   ],
   "source": [
    "text_introduction_for_rap_GPT = input(\"Write something for the RAP GPT to pick up on:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d0e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started from data collection now we here with tha team!\r\n",
      "Wo doubbly, no more, they all in one mistake\r\n",
      "And everything I do or say today that I was first up\r\n",
      "Picked up the pen, and that's when I drew my first blooded\r\n",
      "Zeal bus for the semi-seat her who shade shit\r\n",
      "\r\n",
      "You ride't like a told now, it's the bed we made\r\n",
      "You might also like\r\n",
      "Uh, I can't exactly explain wid-way open like they so I passed you\r\n",
      "Eating my gas fume, got me thinking like for his thoughts\r\n",
      "And that really goil to find who we as instage Vocar\r\n",
      "Of life ins deforetty and the front door\r\n",
      "You might also like\r\n",
      "This a motherfuckin' numbers, this you're in for the Era\r\n",
      "She tell me that the pussy mines, I can hit anytime (Any I drip wishough Cat' lane\r\n",
      "Now of guns and girls that I ain't said that I was dissin'\r\n",
      "Instead, we found this beat and started riffin'\r\n",
      "Shit had me reminiscin', reminiscin' like it's all her pash\r\n",
      "These fake niggas sublime, light for fine sights shit\r\n",
      "So nigga through my veose the mental plane times that I from dro?\r\n",
      "Ane way show it hit ya, it's no warned\r\n",
      " \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 12.038662910461426\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([text_introduction_for_rap_GPT])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3514ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack_project_1",
   "language": "python",
   "name": "ironhack_project_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
